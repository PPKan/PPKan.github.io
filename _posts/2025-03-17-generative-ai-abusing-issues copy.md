---
layout: post
title: "從網路安全淺談 AI 工具的一體兩面"
subtitle: "低門檻高知識犯罪的問題"
date: 2025-03-17
author: "Peter"
header-img: "img/post-bg-hack.jpg"
tags: [資安, 網路, 安全]
---

隨著生成式AI的崛起，各式各樣的 AI 工具讓我們可以做出以前從未想過做得到的事情。AI 模型在迭代之下，在多數知識領域內已經可以比肩專家，又隨著 Anthropic 的 [Model Context Protocol][1] 協定的公布，有了更多的方法可以讓 AI 自行去模擬、發揮。人類只靠隻字片語便可以完成電腦上操作的日子指日可待。

只是，乍聽之下美好的現實是否真是如此？一切的美好總會有其陰暗面，而陰影已經在網路安全領域逐漸擴散。



###  AI 已成為駭客的代理人

關於生成式 AI 對網路社會已經造成的影響，可以從新聞中略窺一二。

首先是這則來自[聯合報][2]的新聞：

> **日本3名國高中生用ChatGPT寫程式 註冊逾百組行動電話門號轉賣**
>
> **日本3名青少年涉嫌利用生成式AI協助開發的程式，非法登入電信公司的系統，註冊大量門號轉賣**，獲利台幣168萬元等值的加密貨幣。警方已經逮捕3人，一人是高一學生、2人是國三學生。
>
> NHK報導，警視廳調查，這3名學生**透過加密通訊程式Telegram購買超過30億組樂天行動通信（Rakuten Mobile）客戶的ID與密碼**，利用自已開發的程式，自動輸入 ID、密碼登入，一旦成功立即申請門號，囤積大量門號。樂天行動通信允許單一ID註冊15組門號。他們從2023年5月至8月期間，註冊了超過100個門號，被控違反「禁止非法存取法」及「電子計算機使用詐欺罪」。
>
> 被逮捕的3人分別是岐阜縣大垣市的16歲高一生、滋賀縣米原市15歲國三生，及東京都立川市的14歲國三生。警方指出，3名青少年透過線上遊戲認識。他們供稱：「我們想設計一種高級犯罪手法，以便在社群媒體上引起關注。」並說，賺到的錢主要用於線上賭博等娛樂。
>
> 3人自學程式設計，**詢問ChatGPT如何簡化操作流程、提升處理速度，持續改良程式**。他們透過Telegram將非法取得的新門號轉賣給多名買家，警方推估他們獲得750萬日圓的加密貨幣作為報酬。

在這個事件當中，國高中生在近乎沒有受過正規網路教育的情況下，自行使用 AI 工具撰寫了自動化程式惡意利用網路取得的個人資料。在過去，就算有心犯罪的人從非法途徑裡得到了大量的個資，在缺乏網路知識的情況下是很難有效地利用這些資料去做大量的註冊。因為網路的自動化操作需要對通訊協定、加密機制、爬蟲等等有一定的了解才有辦法執行，一個完全的素人要學會這些東西至少需要花好一陣子。

同樣的情況不只一例，在同樣的新聞下我們可以看到記者引用了另外一個事件，一名日本男子在沒有相關背景知識下，僅靠生成式 AI 即製作了勒索軟體。

> **疑為日本首例 男子用生成式AI製病毒遭逮**
>
> 日本1名男子疑似使用對話型生成式人工智慧（生成式AI）製作電腦病毒，已被東京都警視廳依法逮捕。日本經濟新聞指出，這很可能是日本警方首度查獲用生成式AI製作病毒的案例。
>
> 綜合時事通信社等媒體報導，警視廳網路犯罪對策課今天說明，這名男嫌2023年3月疑似透過電腦、智慧型手機，使用不只一個公開免費的對話型生成式AI，得手不當程式的設計資訊，並製作了類似勒索病毒的東西。
>
> 這名25歲男嫌已向警方坦承犯案，目前未傳出有人或機構因而受害。
>
> 警視廳指出，這名男嫌並無資訊工程相關的資格或學歷，並供稱「使用AI的話也許能製作（病毒），便蒐集了相關資訊」。警視廳今年3月懷疑這名男子使用偽造的身分證非法購買手機SIM卡，依照詐欺罪嫌等逮捕了這名男子，並在搜查過程中發現他製作的病毒。

[趨勢科技的日本中心甚至對這個事件做出了考察][3]，指謫出惡用生成式 AI 的情況已非個案，甚至有專門訓練出來的惡意 GPT 可以使用。種種案件都展現出了一個共同點，即為，**生成式 AI 的普及大幅降低了犯罪的門檻**。任何有意犯罪；抑或只是覺得一時好玩的人都有了可以自行組織完成犯罪的能力。



### 素人惡意利用 AI 的危險性

對於素人試圖利用 AI 進行犯罪的情況，網路上似乎討論得並不多。對於 AI 的危險性還是多聚焦於技術上，例如利用 AI 判讀原始碼找出攻擊缺口，或是預防利用 AI 進行的自動化攻擊。例如[台灣的趨勢科技在 iThome 的新聞稿][4]中說到：

> 生成式AI的進步將讓駭客的攻擊更隱匿、高效，預期2025 年，駭客將全力開發AI的應用範疇使網路犯罪更具毀滅性。面對不可逆的AI進程，全球資安風險和壓力勢必加劇，企業應化被動為主動，採用一套風險導向的資安方案做整體風險評估與管理；而作為AI世代的公民，人人皆需強化資安意識，以期能負責任並安全地使用AI。

整體的氛圍也是這樣，對於 AI 防護多還是企業、個人如何試圖去應對組織來的威脅。但從個人端來的威脅呢？除了上述日本趨勢的文章之外，[Anthropic CEO Dario 對這個問題給出了很好的洞見][5]。

> **這些模型的能力，以及它們能夠解決生物學、神經科學、經濟發展、治理與和平、經濟許多領域的問題，這樣強大的能力當然也伴隨著風險，對吧？**「能力越大，責任越大」，這兩件事是相伴而生的。[...]
>
> 其中之一，就是我所謂的「災難性的濫用」。**這些濫用行為可能發生在網路、生物、輻射、核子等領域。如果情況真的非常糟糕，這些模型可能會對成千上萬、甚至數百萬人的生命造成傷害甚至致命的威脅。預防這種濫用行為必須是我們的首要之務**。這裡我只想提出一個簡單的觀察：當我看看今天世界上真正做出非常糟糕事情的人們時，我認為人類之所以能受到某種程度的保護，是因為擁有高智商、高教育背景的人與那些想要做出真正恐怖行為的人之間的交集通常很小。
>
> **假設我是一個在這個領域擁有博士學位、工作收入豐厚的人，對我而言有太多東西可以失去。即使假設我完全是邪惡的——而大多數人並非如此——為什麼這樣的人要冒著失去生命、破壞遺產和聲譽的風險，去做一些真正邪惡的事情呢？**如果有更多這種人存在，世界將會是一個更加危險的地方。因此，我擔憂的是，**人工智慧作為一個更聰明的代理人，可能會打破這種相關性**。

Dario 在去年底接受 Lex Fridman 的訪談時即提出了素人使用 AI 進行犯罪的危險性。Dario 將這個行為稱作「災難性的濫用」，有能力去達成犯罪的人們通常享有一定的社會地位，並且會對社會地位約束而降低進行犯罪的可能性，而生成式 AI 正在打破這個框架。

話雖如此，我們在 Dario 的話中卻看不到 Anthropic 是打算怎麼去解決這個問題，他們試圖從模型角度去做調整，讓模型不會吐出有害於人類社會的資訊，盡可能地降低對人類社會的危害。但，AI 的限制有多麼容易被繞過是眾所周知的事實，在針對一些真正危險的領域，例如核子武器，或許可以在訓練資料上做限制，但對於其他沒有直接危險性的領域則非常困難。

一如標題所說的一體兩面，我們在享受 AI 帶來的知識的同時，也造就了犯罪者的溫床。而這個問題所涉略的層面非常廣，幾乎等於每一個領域都要去重新審視結構，讓犯罪者雖然獲得了知識，但沒有那麼容易去執行犯罪。



### 互不信任的封閉時代

面對可能發生的大量高知識犯罪，想當然地需要認真面對，也需要各個單位的協調。對於網路犯罪來說，網路犯罪的工具非常簡單，只要網路跟電腦就可以完成，而且知識如同上述一般地唾手可得，連阻斷犯罪者攝取惡意知識都是癡人說夢。在面對大量且高度專業的攻擊者來說，做為被攻擊對象的個人或企業似乎只能向內縮，盡可能地減少自身網路對外的暴露。

就如同樂天的網站一樣，當我們開放了給任意客戶註冊門號的功能，這個平台就會成為被攻擊的窗口。儘管這個平台看似沒有問題，但在網路世界裡頭，只要有個 input box ，駭客就能把家譜都翻出來。對於大量網路犯罪問題的解法除了同樣也利用 AI 工具加大防禦量能之外，似乎也只能盡量地去限縮功能，封鎖大部分的介面，只讓符合資格的用戶去進行特定操作。大公司當然有辦法做成大角度大範圍的防禦，但其他公司就只能把自己鎖好，想辦法別踏進這座黑暗森林裡。

在這個生成式 AI 流行的看似十分美好的時代裡，應對網路威脅的方法是想辦法將自己轉為封閉。這段聽起來十分諷刺的做法卻是我在看完這些新聞後唯一想得到的安全防禦手段。AI 接下來還會更加的發達，而相對的犯罪也會變得更加流行。希望在接下來的日子裡，人們可以在享受 AI 帶來的便利的同時，也可以有更多的方法避免大規模的針對性 AI 攻擊。



---

感謝閱讀。本文同步發表於FB粉絲專頁 [PP學習筆記](https://www.facebook.com/pplearningnote)，歡迎分享與留言討論。





[1]: https://www.anthropic.com/news/model-context-protocol
[2]: https://udn.com/news/story/6809/8577196
[3]: https://www.trendmicro.com/ja_jp/jp-security/24/e/breaking-securitynews-20240529-02.html
[4]: https://www.ithome.com.tw/pr/166547
[5]: https://youtu.be/ugvHCXCOmm4?si=mv2Te5STVXbsbiQI&amp;t=3289